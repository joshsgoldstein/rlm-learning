# Core LLM
LLM_PROVIDER=openai
LLM_MODEL=gpt-4o-mini
LLM_BASE_URL=https://api.openai.com
# Optional generic API key used by some non-OpenAI/Anthropic providers.
LLM_API_KEY=
# 0 = auto-detect from model; set explicitly to override.
LLM_CONTEXT_WINDOW=0
OPENAI_API_KEY=sk-...
ANTHROPIC_API_KEY=
LLM_TEMPERATURE=0.3

# RLM behavior
ENABLED_APPROACHES=rlm,traditional
RLM_MAX_ITERATIONS=10
RLM_HARD_MAX_ITERATIONS=60
RLM_SANDBOX_EXEC_TIMEOUT_S=5.0
RLM_SANDBOX_MAX_EXEC_LINES=50000
RLM_MAX_HISTORY_MESSAGES=8
RLM_TEST_QUERY=What are the top themes across the reports?

# Data paths
RLM_DATA_DIR=data
RLM_PROCESSED_DIR=processed_data

# RAG baseline (Weaviate + external OpenAI embeddings)
RAG_WEAVIATE_MODE=local
RAG_WEAVIATE_COLLECTION=RLMChunk
RAG_TOP_K=10
RAG_RETRIEVAL_MODE=semantic
RAG_HYBRID_ALPHA=0.7
RAG_EMBEDDING_MODEL=text-embedding-3-small
RAG_AUTO_BOOTSTRAP=true
RAG_INGEST_MAX_CHARS=1800
RAG_INGEST_BATCH_SIZE=64
# optional override for embeddings endpoint
OPENAI_BASE_URL=https://api.openai.com

# Semantic similarity metric backend for eval/autoeval
# - llm: uses semantic_judge.txt via judge LLM
# - vector: cosine similarity of embeddings
SEMANTIC_SIMILARITY_BACKEND=vector
SEMANTIC_EMBED_PROVIDER=openai
SEMANTIC_EMBED_MODEL=text-embedding-3-small
SEMANTIC_EMBED_BASE_URL=https://api.openai.com
# Optional; defaults to OPENAI_API_KEY for openai provider
SEMANTIC_EMBED_API_KEY=

# LLM judge overrides (used when SEMANTIC_SIMILARITY_BACKEND=llm)
JUDGE_LLM_PROVIDER=openai
JUDGE_LLM_MODEL=gpt-4o-mini
JUDGE_LLM_BASE_URL=https://api.openai.com
JUDGE_LLM_API_KEY=
JUDGE_LLM_TEMPERATURE=0.0
# Strict JSON-output repair retries for judge output parsing.
JUDGE_JSON_RETRIES=1

# Optional trace output path for TraceTree tooling.
RLM_TRACE_PATH=rlm_trace_tree.json