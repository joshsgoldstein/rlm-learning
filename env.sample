# Core LLM
LLM_PROVIDER=openai
LLM_MODEL=gpt-5-mini
LLM_BASE_URL=https://api.openai.com
# Optional generic API key used by some non-OpenAI/Anthropic providers.
LLM_API_KEY=
# 0 = auto-detect from model; set explicitly to override.
LLM_CONTEXT_WINDOW=0
OPENAI_API_KEY=sk-...
ANTHROPIC_API_KEY=
LLM_TEMPERATURE=0.3

# RLM behavior
ENABLED_APPROACHES=rlm,traditional
RLM_MAX_ITERATIONS=10
RLM_HARD_MAX_ITERATIONS=60
RLM_SANDBOX_EXEC_TIMEOUT_S=5.0
RLM_SANDBOX_MAX_EXEC_LINES=50000
RLM_MAX_HISTORY_MESSAGES=8
RLM_TEST_QUERY=What are the top themes across the reports?

# Data paths
RLM_DATA_DIR=data
# Optional override for where extracted PDF pages are stored.
# By default this is auto-resolved to <RLM_DATA_DIR>/processed_data.
RLM_PROCESSED_DIR=
# Source selection: auto | prefer_processed | data_only | processed_only
RLM_DOC_SOURCE_MODE=auto
# Comma-separated file extensions from RLM_DATA_DIR to include.
# Defaults already include common readable types (pdf/md/txt/json/csv/tsv/yaml/xml/html/log).
RLM_DOC_EXTENSIONS=pdf,md,markdown,txt,json,csv,tsv,yaml,yml,xml,html,log
# Comma-separated directory names to ignore while scanning RLM_DATA_DIR
RLM_DOC_IGNORE_DIRS=.git,.obsidian,node_modules,venv,.venv,dist,build,__pycache__

# RAG baseline (Weaviate + external OpenAI embeddings)
RAG_WEAVIATE_MODE=local
RAG_WEAVIATE_COLLECTION=RLMChunk
RAG_TOP_K=10
RAG_RETRIEVAL_MODE=semantic
RAG_HYBRID_ALPHA=0.7
RAG_EMBEDDING_MODEL=text-embedding-3-small
RAG_AUTO_BOOTSTRAP=true
RAG_INGEST_MAX_CHARS=1800
RAG_INGEST_BATCH_SIZE=64
# optional override for embeddings endpoint
OPENAI_BASE_URL=https://api.openai.com

# Semantic similarity metric backend for eval/autoeval
# - llm: uses semantic_judge.txt via judge LLM
# - vector: cosine similarity of embeddings
SEMANTIC_SIMILARITY_BACKEND=vector
SEMANTIC_EMBED_PROVIDER=openai
SEMANTIC_EMBED_MODEL=text-embedding-3-small
SEMANTIC_EMBED_BASE_URL=https://api.openai.com
# Optional; defaults to OPENAI_API_KEY for openai provider
SEMANTIC_EMBED_API_KEY=

# LLM judge overrides (used when SEMANTIC_SIMILARITY_BACKEND=llm)
JUDGE_LLM_PROVIDER=openai
JUDGE_LLM_MODEL=gpt-5-mini
JUDGE_LLM_BASE_URL=https://api.openai.com
JUDGE_LLM_API_KEY=
JUDGE_LLM_TEMPERATURE=0.0
# Strict JSON-output repair retries for judge output parsing.
JUDGE_JSON_RETRIES=1

# Optional trace output path for TraceTree tooling.
RLM_TRACE_PATH=rlm_trace_tree.json